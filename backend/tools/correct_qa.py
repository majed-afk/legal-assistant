#!/usr/bin/env python3
"""
ØªØµØ­ÙŠØ­ 208 Ø¥Ø¬Ø§Ø¨Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Claude + Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø±Ø³Ù…ÙŠØ©
Corrects all 208 Q&A answers using Claude API and official law text.

Usage:
    python -m backend.tools.correct_qa
    python -m backend.tools.correct_qa --start 50  # Resume from Q&A #50
    python -m backend.tools.correct_qa --ids 30,46,52  # Correct specific IDs only
"""

import json
import os
import re
import sys
import time
import argparse
import openpyxl
import anthropic
from pathlib import Path
from dotenv import load_dotenv

# Load env
ROOT = Path(__file__).resolve().parent.parent.parent
load_dotenv(ROOT / ".env")

ARTICLES_PATH = ROOT / "backend" / "data" / "ahwal_clean_articles.json"
QA_EXCEL_PATH = ROOT.parent / "Downloads" / "legal_qa_208_complete.xlsx"
OUTPUT_PATH = ROOT / "backend" / "data" / "corrected_qa.json"
PROGRESS_PATH = ROOT / "backend" / "data" / "correction_progress.json"


def load_articles():
    """Load all clean articles indexed by article number."""
    with open(ARTICLES_PATH, "r", encoding="utf-8") as f:
        articles = json.load(f)
    index = {}
    for a in articles:
        index[a["article_number"]] = a
    return index


def load_qa_from_excel():
    """Load 208 Q&A entries from Excel file."""
    wb = openpyxl.load_workbook(QA_EXCEL_PATH, read_only=True)
    ws = wb.active
    entries = []
    for row in ws.iter_rows(min_row=5, max_row=ws.max_row, values_only=True):
        if not row[0]:
            continue
        entry = {
            "id": int(row[0]),
            "category": row[1] or "",
            "chapter": row[2] or "",
            "section": row[3] or "",
            "question_formal": row[4] or "",
            "question_colloquial": row[5] or "",
            "original_answer": row[6] or "",
            "cited_articles_raw": row[7] or "",
        }
        entries.append(entry)
    wb.close()
    return entries


def parse_article_numbers(raw: str) -> list[int]:
    """Extract article numbers from Ø§Ù„Ù…ÙˆØ§Ø¯ column."""
    numbers = re.findall(r'(\d+)', str(raw))
    return [int(n) for n in numbers]


def get_relevant_articles(article_nums: list[int], articles_index: dict, context_range: int = 3) -> str:
    """Get text of cited articles + nearby articles for context."""
    all_nums = set()
    for num in article_nums:
        # Add the cited article + nearby articles
        for i in range(max(1, num - context_range), num + context_range + 1):
            if i in articles_index:
                all_nums.add(i)

    result_parts = []
    for num in sorted(all_nums):
        a = articles_index[num]
        marker = " â¬…ï¸ [Ù…ÙØ³ØªØ´Ù‡Ø¯ Ø¨Ù‡Ø§]" if num in article_nums else ""
        result_parts.append(
            f"Ø§Ù„Ù…Ø§Ø¯Ø© ({num}){marker} â€” {a['topic']} â€” {a['chapter']} > {a['section']}:\n{a['text']}"
        )
    return "\n\n".join(result_parts)


CORRECTION_PROMPT = """Ø£Ù†Øª Ù…Ø¯Ù‚Ù‚ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø­ÙˆØ§Ù„ Ø§Ù„Ø´Ø®ØµÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ.

Ù…Ù‡Ù…ØªÙƒ: ØªØµØ­ÙŠØ­ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø£Ø¯Ù†Ø§Ù‡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø±Ø³Ù…ÙŠØ© Ø§Ù„Ù…Ø±ÙÙ‚Ø©.

## Ø§Ù„Ø³Ø¤Ø§Ù„ (ÙØµØ­Ù‰):
{question_formal}

## Ø§Ù„Ø³Ø¤Ø§Ù„ (Ø¹Ø§Ù…ÙŠ):
{question_colloquial}

## Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© (ØªØ­ØªØ§Ø¬ ØªØµØ­ÙŠØ­):
{original_answer}

## Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…ÙØ³ØªØ´Ù‡Ø¯ Ø¨Ù‡Ø§ Ø£ØµÙ„Ø§Ù‹:
{cited_articles_raw}

## Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø±Ø³Ù…ÙŠØ© Ù„Ù„Ù…ÙˆØ§Ø¯ (Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„ÙˆØ­ÙŠØ¯ Ù„Ù„Ø­Ù‚ÙŠÙ‚Ø©):
{articles_text}

## ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªØµØ­ÙŠØ­:
1. **ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø¯**: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø±Ù‚Ù… Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ù…Ø°ÙƒÙˆØ± ÙÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø®Ø§Ø·Ø¦Ø§Ù‹ØŒ ØµØ­Ø­Ù‡ Ù„Ù„Ø±Ù‚Ù… Ø§Ù„ØµØ­ÙŠØ­ Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ Ø£Ø¹Ù„Ø§Ù‡.
2. **ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§Ù‚ØªØ¨Ø§Ø³Ø§Øª**: Ø£ÙŠ Ù†Øµ Ø¨ÙŠÙ† Ø¹Ù„Ø§Ù…ØªÙŠ ØªÙ†ØµÙŠØµ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù…Ø·Ø§Ø¨Ù‚Ø§Ù‹ Ø­Ø±ÙÙŠØ§Ù‹ Ù„Ù„Ù†Øµ Ø§Ù„Ø±Ø³Ù…ÙŠ. ØµØ­Ø­ Ø£ÙŠ Ø§Ù‚ØªØ¨Ø§Ø³ Ù…Ø­Ø±Ù‘Ù.
3. **ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©**: Ø§Ù„Ù…Ø¯Ø¯ØŒ Ø§Ù„Ø£Ø¹Ù…Ø§Ø±ØŒ Ø§Ù„Ø­Ù‚ÙˆÙ‚ØŒ Ø§Ù„Ø´Ø±ÙˆØ· â€” ÙŠØ¬Ø¨ Ø£Ù† ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù†Øµ Ø§Ù„Ø±Ø³Ù…ÙŠ ØªÙ…Ø§Ù…Ø§Ù‹.
4. **Ø­Ø¯Ø¯ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ØµØ­ÙŠØ­Ø©**: Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…ÙØ³ØªØ´Ù‡Ø¯ Ø¨Ù‡Ø§ Ø£ØµÙ„Ø§Ù‹ Ø®Ø§Ø·Ø¦Ø©ØŒ Ø­Ø¯Ø¯ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ØµØ­ÙŠØ­Ø© Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø±ÙÙ‚Ø©.
5. **Ù„Ø§ ØªØ®ØªØ±Ø¹**: Ù„Ø§ ØªØ¶Ù Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø±Ø³Ù…ÙŠØ©.

## Ø´ÙƒÙ„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ (JSON):
Ø£Ø¬Ø¨ Ø¨Ù€ JSON ÙÙ‚Ø· Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø´ÙƒÙ„:
{{
    "corrected_answer": "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù…ØµØ­Ø­Ø© ÙƒØ§Ù…Ù„Ø© Ø¨Ù†ÙØ³ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ (ğŸ“– Ø§Ù„Ø³Ù†Ø¯ Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠ + ğŸ“‹ Ø§Ù„ØªÙØµÙŠÙ„ + ğŸ“Œ Ù…Ù„Ø§Ø­Ø¸Ø§Øª + âš ï¸ ØªØ­Ø°ÙŠØ±Ø§Øª)",
    "corrected_articles": ["Ø§Ù„Ù…Ø§Ø¯Ø© X", "Ø§Ù„Ù…Ø§Ø¯Ø© Y"],
    "changes_made": ["ÙˆØµÙ Ù…Ø®ØªØµØ± Ù„ÙƒÙ„ ØªØºÙŠÙŠØ± ØªÙ…"],
    "severity": "none|minor|major|critical"
}}

Ø£Ø¬Ø¨ Ø¨Ù€ JSON ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù†Øµ Ø¥Ø¶Ø§ÙÙŠ."""


def correct_single_qa(client, entry: dict, articles_index: dict) -> dict:
    """Correct a single Q&A entry using Claude API."""
    # Parse cited articles
    cited_nums = parse_article_numbers(entry["cited_articles_raw"])

    # Get relevant article texts (cited + nearby for context)
    articles_text = get_relevant_articles(cited_nums, articles_index, context_range=5)

    # Build prompt
    prompt = CORRECTION_PROMPT.format(
        question_formal=entry["question_formal"],
        question_colloquial=entry["question_colloquial"],
        original_answer=entry["original_answer"],
        cited_articles_raw=entry["cited_articles_raw"],
        articles_text=articles_text,
    )

    # Call Claude
    response = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=2000,
        messages=[{"role": "user", "content": prompt}],
    )

    raw_text = response.content[0].text.strip()

    # Parse JSON from response
    # Handle markdown code blocks
    if "```json" in raw_text:
        raw_text = raw_text.split("```json")[1].split("```")[0].strip()
    elif "```" in raw_text:
        raw_text = raw_text.split("```")[1].split("```")[0].strip()

    try:
        result = json.loads(raw_text)
    except json.JSONDecodeError:
        result = {
            "corrected_answer": raw_text,
            "corrected_articles": [f"Ø§Ù„Ù…Ø§Ø¯Ø© {n}" for n in cited_nums],
            "changes_made": ["ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ JSON â€” Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø®Ø§Ù… Ù…Ø­ÙÙˆØ¸Ø©"],
            "severity": "unknown",
        }

    return {
        "id": entry["id"],
        "category": entry["category"],
        "question_formal": entry["question_formal"],
        "question_colloquial": entry["question_colloquial"],
        "original_answer": entry["original_answer"],
        "original_articles": entry["cited_articles_raw"],
        "corrected_answer": result.get("corrected_answer", ""),
        "corrected_articles": result.get("corrected_articles", []),
        "changes_made": result.get("changes_made", []),
        "severity": result.get("severity", "unknown"),
    }


def load_progress() -> dict:
    """Load correction progress."""
    if PROGRESS_PATH.exists():
        with open(PROGRESS_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    return {"completed_ids": [], "results": []}


def save_progress(progress: dict):
    """Save correction progress."""
    with open(PROGRESS_PATH, "w", encoding="utf-8") as f:
        json.dump(progress, f, ensure_ascii=False, indent=2)


def main():
    parser = argparse.ArgumentParser(description="Correct 208 Q&A entries")
    parser.add_argument("--start", type=int, default=1, help="Start from Q&A ID")
    parser.add_argument("--ids", type=str, default="", help="Comma-separated IDs to correct")
    parser.add_argument("--resume", action="store_true", help="Resume from last progress")
    args = parser.parse_args()

    # Load data
    print("ğŸ“š ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©...")
    articles_index = load_articles()
    print(f"   âœ… {len(articles_index)} Ù…Ø§Ø¯Ø©")

    print("ğŸ“‹ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø£Ø¬ÙˆØ¨Ø©...")
    qa_entries = load_qa_from_excel()
    print(f"   âœ… {len(qa_entries)} Ø³Ø¤Ø§Ù„")

    # Filter entries
    if args.ids:
        target_ids = [int(x.strip()) for x in args.ids.split(",")]
        qa_entries = [e for e in qa_entries if e["id"] in target_ids]
        print(f"   ğŸ¯ ØªØµØ­ÙŠØ­ {len(qa_entries)} Ø³Ø¤Ø§Ù„ Ù…Ø­Ø¯Ø¯")
    elif args.start > 1:
        qa_entries = [e for e in qa_entries if e["id"] >= args.start]
        print(f"   ğŸ¯ Ø¨Ø¯Ø¡ Ù…Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ #{args.start}")

    # Load progress
    progress = load_progress() if args.resume else {"completed_ids": [], "results": []}
    completed_ids = set(progress["completed_ids"])

    # Skip already completed
    if args.resume:
        qa_entries = [e for e in qa_entries if e["id"] not in completed_ids]
        print(f"   â­ï¸ ØªØ®Ø·ÙŠ {len(completed_ids)} Ø³Ø¤Ø§Ù„ Ù…ÙƒØªÙ…Ù„ØŒ Ù…ØªØ¨Ù‚ÙŠ {len(qa_entries)}")

    # Initialize Claude client
    api_key = os.getenv("ANTHROPIC_API_KEY", "")
    if not api_key:
        print("âŒ ANTHROPIC_API_KEY ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ .env")
        sys.exit(1)

    client = anthropic.Anthropic(api_key=api_key)

    # Process each entry
    stats = {"none": 0, "minor": 0, "major": 0, "critical": 0, "unknown": 0}
    total = len(qa_entries)

    print(f"\nğŸ”§ Ø¨Ø¯Ø¡ Ø§Ù„ØªØµØ­ÙŠØ­ ({total} Ø³Ø¤Ø§Ù„)...\n")

    for i, entry in enumerate(qa_entries):
        qid = entry["id"]
        print(f"  [{i+1}/{total}] Ø³Ø¤Ø§Ù„ #{qid}: {entry['question_formal'][:60]}...", end=" ", flush=True)

        try:
            result = correct_single_qa(client, entry, articles_index)
            severity = result["severity"]
            stats[severity] = stats.get(severity, 0) + 1

            icon = {"none": "âœ…", "minor": "ğŸ”µ", "major": "ğŸŸ¡", "critical": "ğŸ”´"}.get(severity, "âšª")
            changes = len(result["changes_made"])
            print(f"{icon} {severity} ({changes} ØªØºÙŠÙŠØ±)")

            # Save progress
            progress["results"].append(result)
            progress["completed_ids"].append(qid)
            save_progress(progress)

            # Rate limiting
            time.sleep(0.5)

        except anthropic.RateLimitError:
            print("â³ rate limit â€” Ø§Ù†ØªØ¸Ø§Ø± 30 Ø«Ø§Ù†ÙŠØ©...")
            time.sleep(30)
            # Retry
            try:
                result = correct_single_qa(client, entry, articles_index)
                progress["results"].append(result)
                progress["completed_ids"].append(qid)
                save_progress(progress)
                print(f"  âœ… Ù†Ø¬Ø­ Ø¨Ø¹Ø¯ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±")
            except Exception as e2:
                print(f"  âŒ ÙØ´Ù„: {e2}")

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£: {e}")
            continue

    # Save final output
    # Merge with any previous results
    all_results = {r["id"]: r for r in progress["results"]}
    final_results = sorted(all_results.values(), key=lambda x: x["id"])

    with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
        json.dump(final_results, f, ensure_ascii=False, indent=2)

    # Print summary
    print(f"\n{'='*60}")
    print(f"ğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„ØªØµØ­ÙŠØ­:")
    print(f"   âœ… Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±: {stats['none']}")
    print(f"   ğŸ”µ ØªØºÙŠÙŠØ±Ø§Øª Ø·ÙÙŠÙØ©: {stats['minor']}")
    print(f"   ğŸŸ¡ ØªØºÙŠÙŠØ±Ø§Øª Ø¬ÙˆÙ‡Ø±ÙŠØ©: {stats['major']}")
    print(f"   ğŸ”´ Ø£Ø®Ø·Ø§Ø¡ Ø­Ø±Ø¬Ø©: {stats['critical']}")
    print(f"   ğŸ“ Ù…Ø­ÙÙˆØ¸ ÙÙŠ: {OUTPUT_PATH}")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()
