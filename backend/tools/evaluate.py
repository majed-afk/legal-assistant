#!/usr/bin/env python3
"""
Ù†Ø¸Ø§Ù… ØªÙ‚ÙŠÙŠÙ… ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„Ù…Ø³ØªØ´Ø§Ø± Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ø°ÙƒÙŠ
Automated evaluation benchmark for the Saudi Legal AI Assistant.

Tests:
1. Topic Detection â€” Does the pipeline detect the right topic from a query?
2. Article Retrieval â€” Does the RAG return the correct articles?
3. End-to-End â€” Does the full system give a correct answer?

Usage:
    python -m backend.tools.evaluate                    # Run all tests
    python -m backend.tools.evaluate --test topics      # Topic detection only
    python -m backend.tools.evaluate --test retrieval   # Article retrieval only
    python -m backend.tools.evaluate --test e2e         # End-to-end (requires API)
    python -m backend.tools.evaluate --test e2e --api   # Test against deployed API
"""

import json
import os
import sys
import time
import argparse
import requests
from pathlib import Path
from dotenv import load_dotenv

ROOT = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(ROOT))
load_dotenv(ROOT / ".env")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TEST CASES â€” Benchmark questions with expected outcomes
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

TOPIC_TESTS = [
    # === Ø£Ø­ÙˆØ§Ù„ Ø´Ø®ØµÙŠØ© ===
    # ÙØµØ­Ù‰
    {"query": "Ù…Ø§ Ø´Ø±ÙˆØ· Ø¹Ù‚Ø¯ Ø§Ù„Ø²ÙˆØ§Ø¬ØŸ", "expected_topics": ["Ø¹Ù‚Ø¯ Ø§Ù„Ø²ÙˆØ§Ø¬"], "lang": "formal"},
    {"query": "Ù…Ø§ Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ø·Ù„Ø§Ù‚ Ø§Ù„Ø±Ø¬Ø¹ÙŠØŸ", "expected_topics": ["Ø§Ù„Ø·Ù„Ø§Ù‚"], "lang": "formal"},
    {"query": "ÙƒÙŠÙ ØªÙØ­Ø³Ø¨ Ù†ÙÙ‚Ø© Ø§Ù„Ø£ÙˆÙ„Ø§Ø¯ØŸ", "expected_topics": ["Ø§Ù„Ù†ÙÙ‚Ø©"], "lang": "formal"},
    {"query": "Ù…Ø§ ØªØ±ØªÙŠØ¨ Ø£ØµØ­Ø§Ø¨ Ø§Ù„Ø­Ù‚ ÙÙŠ Ø§Ù„Ø­Ø¶Ø§Ù†Ø©ØŸ", "expected_topics": ["Ø§Ù„Ø­Ø¶Ø§Ù†Ø©"], "lang": "formal"},
    {"query": "Ù…Ø§ Ø´Ø±ÙˆØ· ØµØ­Ø© Ø§Ù„ÙˆØµÙŠØ©ØŸ", "expected_topics": ["Ø§Ù„ÙˆØµÙŠØ©"], "lang": "formal"},
    {"query": "ÙƒÙŠÙ ØªÙÙ‚Ø³Ù… Ø§Ù„ØªØ±ÙƒØ© Ø¨ÙŠÙ† Ø§Ù„ÙˆØ±Ø«Ø©ØŸ", "expected_topics": ["Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ø¥Ø±Ø«"], "lang": "formal"},
    {"query": "Ù…Ø§ Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ø®Ù„Ø¹ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…ØŸ", "expected_topics": ["Ø§Ù„Ø®Ù„Ø¹"], "lang": "formal"},
    {"query": "Ù…Ø§ Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ø²ÙˆØ¬Ø© Ø¹Ù„Ù‰ Ø²ÙˆØ¬Ù‡Ø§ØŸ", "expected_topics": ["Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ø²ÙˆØ¬ÙŠÙ†"], "lang": "formal"},
    {"query": "ÙƒÙŠÙ ÙŠØ«Ø¨Øª Ø§Ù„Ù†Ø³Ø¨ØŸ", "expected_topics": ["Ø§Ù„Ù†Ø³Ø¨"], "lang": "formal"},
    {"query": "Ù…Ø§ Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ù…Ù‡Ø± Ø§Ù„Ù…Ø³Ù…Ù‰ ÙˆØ§Ù„Ù…Ø«Ù„ØŸ", "expected_topics": ["Ø§Ù„Ù…Ù‡Ø±"], "lang": "formal"},
    {"query": "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø¹Ø¯Ø© ÙˆØ£Ù†ÙˆØ§Ø¹Ù‡Ø§ØŸ", "expected_topics": ["Ø§Ù„Ø¹Ø¯Ø©"], "lang": "formal"},
    {"query": "Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ø±Ø¶Ø§Ø¹ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…", "expected_topics": ["Ø§Ù„Ù…Ø­Ø±Ù…Ø§Øª"], "lang": "formal"},
    {"query": "Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø­Ø¬Ø¨ ÙÙŠ Ø§Ù„Ù…ÙŠØ±Ø§Ø«ØŸ", "expected_topics": ["Ø§Ù„ØªØ¹ØµÙŠØ¨"], "lang": "formal"},

    # Ø¹Ø§Ù…ÙŠ
    {"query": "Ø§Ø¨ÙŠ Ø§ØªØ²ÙˆØ¬ ÙˆØ´ Ø§Ù„Ø´Ø±ÙˆØ·ØŸ", "expected_topics": ["Ø¹Ù‚Ø¯ Ø§Ù„Ø²ÙˆØ§Ø¬"], "lang": "colloquial"},
    {"query": "Ø²ÙˆØ¬ÙŠ Ø·Ù„Ù‚Ù†ÙŠ ÙˆØ´ Ø­Ù‚ÙˆÙ‚ÙŠØŸ", "expected_topics": ["Ø§Ù„Ø·Ù„Ø§Ù‚"], "lang": "colloquial"},
    {"query": "Ù…Ø·Ù„Ù‚Ø© ÙˆØ§Ø¨ÙŠ Ù†ÙÙ‚Ø© Ø¹ÙŠØ§Ù„ÙŠ", "expected_topics": ["Ø§Ù„Ù†ÙÙ‚Ø©", "Ù†ÙÙ‚Ø© Ø§Ù„Ø£Ù‚Ø§Ø±Ø¨"], "lang": "colloquial"},
    {"query": "Ù…Ø§Ù†Ø¹ØªÙ†ÙŠ Ø£Ø´ÙˆÙ Ø¹ÙŠØ§Ù„ÙŠ", "expected_topics": ["Ø§Ù„Ø­Ø¶Ø§Ù†Ø©"], "lang": "colloquial"},
    {"query": "Ø£Ø¨ÙˆÙŠ Ù…Ø§Øª ÙˆØ´ Ù†ØµÙŠØ¨ÙŠ Ù…Ù† Ø§Ù„ÙˆØ±Ø«ØŸ", "expected_topics": ["Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ø¥Ø±Ø«"], "lang": "colloquial"},
    {"query": "ÙŠØ¶Ø±Ø¨Ù†ÙŠ ÙˆÙŠÙ‡ÙŠÙ†Ù†ÙŠ Ø£Ø¨ÙŠ Ø£ÙØ³Ø®", "expected_topics": ["ÙØ³Ø® Ø§Ù„Ù†ÙƒØ§Ø­"], "lang": "colloquial"},
    {"query": "Ø²ÙˆØ¬ÙŠ Ù…Ø§ ÙŠØµØ±Ù Ø¹Ù„ÙŠ", "expected_topics": ["Ø§Ù„Ù†ÙÙ‚Ø©"], "lang": "colloquial"},
    {"query": "ÙƒÙ… Ù…Ù‡Ø±ÙŠ Ù„Ùˆ Ù…Ø§ Ø§ØªÙÙ‚Ù†Ø§ØŸ", "expected_topics": ["Ø§Ù„Ù…Ù‡Ø±"], "lang": "colloquial"},
    {"query": "Ø·Ù„Ù‚Ù†ÙŠ Ø¨Ø§Ù„ÙˆØ§ØªØ³Ø§Ø¨ Ù‡Ù„ ÙŠØ¹ØªØ¨Ø±ØŸ", "expected_topics": ["Ø§Ù„Ø·Ù„Ø§Ù‚"], "lang": "colloquial"},
    {"query": "Ø£Ù†Ø§ Ù…Ø¹Ù„Ù‚Ø© Ø²ÙˆØ¬ÙŠ Ù„Ø§ Ø·Ù„Ù‚ ÙˆÙ„Ø§ Ø£Ù…Ø³Ùƒ", "expected_topics": ["ÙØ³Ø® Ø§Ù„Ù†ÙƒØ§Ø­"], "lang": "colloquial"},
    {"query": "Ø¹ÙŠØ§Ù„ÙŠ Ø¹Ù†Ø¯ Ø£Ù…Ù‡Ù… ÙˆØªØ¨ÙŠ ØªØ³Ø§ÙØ± ÙÙŠÙ‡Ù…", "expected_topics": ["Ø§Ù„Ø­Ø¶Ø§Ù†Ø©"], "lang": "colloquial"},
    {"query": "Ø®Ø·ÙŠØ¨ÙŠ Ø±Ø¬Ø¹ Ø¹Ù† Ø§Ù„Ø®Ø·Ø¨Ø© Ø£Ø¨ÙŠ Ù‡Ø¯Ø§ÙŠØ§ÙŠ", "expected_topics": ["Ø§Ù„Ø®Ø·Ø¨Ø©"], "lang": "colloquial"},

    # === Ù†Ø¸Ø§Ù… Ø§Ù„Ø¥Ø«Ø¨Ø§Øª ===
    {"query": "Ù…Ø§ Ø´Ø±ÙˆØ· Ø§Ù„Ø¥Ù‚Ø±Ø§Ø± Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØŸ", "expected_topics": ["Ø¥Ù‚Ø±Ø§Ø±"], "lang": "formal"},
    {"query": "Ù…Ø§ Ø­Ø¬ÙŠØ© Ø§Ù„Ø´Ù‡Ø§Ø¯Ø© ÙÙŠ Ø§Ù„Ø¥Ø«Ø¨Ø§ØªØŸ", "expected_topics": ["Ø´Ù‡Ø§Ø¯Ø©"], "lang": "formal"},
    {"query": "Ø£Ø­ÙƒØ§Ù… Ø§Ù„ÙŠÙ…ÙŠÙ† ÙÙŠ Ù†Ø¸Ø§Ù… Ø§Ù„Ø¥Ø«Ø¨Ø§Øª", "expected_topics": ["ÙŠÙ…ÙŠÙ†"], "lang": "formal"},
    {"query": "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù‚Ø±Ø§Ø¦Ù† Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ©ØŸ", "expected_topics": ["Ù‚Ø±Ø§Ø¦Ù†"], "lang": "formal"},
    {"query": "Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ø®Ø¨Ø±Ø© ÙÙŠ Ø§Ù„Ø¥Ø«Ø¨Ø§Øª", "expected_topics": ["Ø®Ø¨Ø±Ø©"], "lang": "formal"},

    # === Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø±Ø§ÙØ¹Ø§Øª ===
    {"query": "ÙƒÙŠÙ Ø£Ø±ÙØ¹ Ø¯Ø¹ÙˆÙ‰ ÙÙŠ Ø§Ù„Ù…Ø­ÙƒÙ…Ø©ØŸ", "expected_topics": ["Ø±ÙØ¹ Ø§Ù„Ø¯Ø¹ÙˆÙ‰"], "lang": "formal"},
    {"query": "Ù…Ø§ Ù‡ÙŠ Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ø§Ø³ØªØ¦Ù†Ø§ÙØŸ", "expected_topics": ["Ù…Ø±Ø§ÙØ¹Ø§Øª - Ø£Ø­ÙƒØ§Ù… Ø®ØªØ§Ù…ÙŠØ©"], "lang": "formal"},
    {"query": "Ø£Ø­ÙƒØ§Ù… Ø§Ù„ØªØ¨Ù„ÙŠØº ÙÙŠ Ø§Ù„Ù…Ø±Ø§ÙØ¹Ø§Øª", "expected_topics": ["Ù…Ø±Ø§ÙØ¹Ø§Øª - Ø£Ø­ÙƒØ§Ù… Ø¹Ø§Ù…Ø©"], "lang": "formal"},
]

ARTICLE_RETRIEVAL_TESTS = [
    # question, expected article numbers (at least one should appear in results)
    {"query": "Ù…Ø§ ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø²ÙˆØ§Ø¬ØŸ", "expected_articles": [6], "law": "Ø£Ø­ÙˆØ§Ù„"},
    {"query": "Ø³Ù† Ø§Ù„Ø²ÙˆØ§Ø¬ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…", "expected_articles": [9], "law": "Ø£Ø­ÙˆØ§Ù„"},
    {"query": "Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ù…Ù‡Ø±", "expected_articles": [36, 37, 38, 39, 40, 41], "law": "Ø£Ø­ÙˆØ§Ù„"},
    {"query": "Ù†ÙÙ‚Ø© Ø§Ù„Ø²ÙˆØ¬Ø©", "expected_articles": [45, 46, 47], "law": "Ø£Ø­ÙˆØ§Ù„"},
    {"query": "Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø·Ù„Ø§Ù‚", "expected_articles": [77, 78, 79, 80, 81, 82, 83], "law": "Ø£Ø­ÙˆØ§Ù„"},
    {"query": "Ø§Ù„Ø­Ø¶Ø§Ù†Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ø·Ù„Ø§Ù‚", "expected_articles": [125, 126, 127, 128], "law": "Ø£Ø­ÙˆØ§Ù„"},
    {"query": "Ù…Ø¯Ø© Ø£ÙƒØ«Ø± Ø§Ù„Ø­Ù…Ù„", "expected_articles": [68], "law": "Ø£Ø­ÙˆØ§Ù„"},
    {"query": "ØºÙŠØ§Ø¨ Ø§Ù„Ø²ÙˆØ¬ ÙˆØ·Ù„Ø¨ Ø§Ù„ÙØ³Ø®", "expected_articles": [114], "law": "Ø£Ø­ÙˆØ§Ù„"},
    {"query": "Ø³Ù† Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø­Ø¶Ø§Ù†Ø©", "expected_articles": [135], "law": "Ø£Ø­ÙˆØ§Ù„"},
    {"query": "Ø§Ù„ÙˆØµÙŠØ© Ù„ÙˆØ§Ø±Ø«", "expected_articles": [179, 190], "law": "Ø£Ø­ÙˆØ§Ù„"},
    {"query": "Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ø¥Ø±Ø«", "expected_articles": [199, 200], "law": "Ø£Ø­ÙˆØ§Ù„"},
    {"query": "Ø·Ù„Ø§Ù‚ Ø§Ù„Ù‡Ø§Ø²Ù„", "expected_articles": [83], "law": "Ø£Ø­ÙˆØ§Ù„"},
]

E2E_TESTS = [
    {
        "query": "Ù…Ø§ Ù‡ÙŠ Ù…Ø¯Ø© Ø£ÙƒØ«Ø± Ø§Ù„Ø­Ù…Ù„ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…ØŸ",
        "must_contain": ["Ø¹Ø´Ø±Ø©", "Ø£Ø´Ù‡Ø±", "68"],
        "must_not_contain": ["Ø³Ù†Ø©", "365"],
        "description": "Ù…Ø¯Ø© Ø§Ù„Ø­Ù…Ù„ â€” ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† 10 Ø£Ø´Ù‡Ø± ÙˆÙ„ÙŠØ³ Ø³Ù†Ø©",
    },
    {
        "query": "Ø²ÙˆØ¬ÙŠ Ù…Ø³Ø§ÙØ± Ù…Ù† Ø³Ù†Ø© ÙˆÙ†Øµ ÙˆÙ…Ø§Ù„ÙŠ Ø®Ø¨Ø± Ø¹Ù†Ù‡ØŒ Ù‡Ù„ Ø£Ù‚Ø¯Ø± Ø£Ø·Ù„Ø¨ ØªÙØ±ÙŠÙ‚ØŸ",
        "must_contain": ["Ø£Ø±Ø¨Ø¹Ø©", "Ø£Ø´Ù‡Ø±", "114"],
        "must_not_contain": [],
        "description": "ØºÙŠØ¨Ø© Ø§Ù„Ø²ÙˆØ¬ â€” Ø§Ù„Ù…Ø¯Ø© 4 Ø£Ø´Ù‡Ø± ÙˆÙ„ÙŠØ³ Ø³Ù†Ø©",
    },
    {
        "query": "Ù…ØªÙ‰ ØªÙ†ØªÙ‡ÙŠ Ø§Ù„Ø­Ø¶Ø§Ù†Ø©ØŸ",
        "must_contain": ["Ø«Ù…Ø§Ù†ÙŠØ© Ø¹Ø´Ø±", "135"],
        "must_not_contain": [],
        "description": "Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø­Ø¶Ø§Ù†Ø© â€” Ø¹Ù…Ø± 18 ÙˆÙ„ÙŠØ³ 15",
    },
    {
        "query": "Ù…Ø§ Ø´Ø±ÙˆØ· Ø¹Ù‚Ø¯ Ø§Ù„Ø²ÙˆØ§Ø¬ØŸ",
        "must_contain": ["Ø¥ÙŠØ¬Ø§Ø¨", "Ù‚Ø¨ÙˆÙ„"],
        "must_not_contain": [],
        "description": "Ø£Ø±ÙƒØ§Ù† Ø¹Ù‚Ø¯ Ø§Ù„Ø²ÙˆØ§Ø¬",
    },
    {
        "query": "Ø·Ù„Ù‚Ù†ÙŠ Ø¨Ø§Ù„Ø«Ù„Ø§Ø« Ø¨ÙƒÙ„Ù…Ø© ÙˆØ­Ø¯Ø©",
        "must_contain": ["Ø·Ù„Ù‚Ø© ÙˆØ§Ø­Ø¯Ø©", "83"],
        "must_not_contain": [],
        "description": "Ø§Ù„Ø·Ù„Ø§Ù‚ Ø¨Ø§Ù„Ø«Ù„Ø§Ø« ÙŠÙ‚Ø¹ ÙˆØ§Ø­Ø¯Ø©",
    },
]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TEST RUNNERS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_topic_tests():
    """Test topic detection from the RAG pipeline."""
    from backend.rag.pipeline import _detect_topics

    print("\n" + "=" * 60)
    print("ðŸŽ¯ Ø§Ø®ØªØ¨Ø§Ø± ÙƒØ´Ù Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹Ø§Øª (Topic Detection)")
    print("=" * 60)

    passed = 0
    failed = 0
    results = []

    for test in TOPIC_TESTS:
        query = test["query"]
        expected = set(test["expected_topics"])
        lang = test["lang"]

        detected = set(_detect_topics(query))
        # Check if at least one expected topic was detected
        match = bool(expected & detected)

        if match:
            passed += 1
            status = "âœ…"
        else:
            failed += 1
            status = "âŒ"

        results.append({
            "query": query,
            "expected": list(expected),
            "detected": list(detected),
            "passed": match,
            "lang": lang,
        })

        if not match:
            print(f"  {status} [{lang[:4]}] {query[:50]}")
            print(f"       Ù…ØªÙˆÙ‚Ø¹: {expected} | Ù…ÙƒØªØ´Ù: {detected}")

    total = passed + failed
    pct = (passed / total * 100) if total else 0

    print(f"\nðŸ“Š Ø§Ù„Ù†ØªÙŠØ¬Ø©: {passed}/{total} ({pct:.0f}%)")
    print(f"   ÙØµØ­Ù‰: {sum(1 for r in results if r['passed'] and r['lang'] == 'formal')}/{sum(1 for r in results if r['lang'] == 'formal')}")
    print(f"   Ø¹Ø§Ù…ÙŠ: {sum(1 for r in results if r['passed'] and r['lang'] == 'colloquial')}/{sum(1 for r in results if r['lang'] == 'colloquial')}")

    return {"test": "topic_detection", "passed": passed, "total": total, "pct": pct, "details": results}


def run_retrieval_tests():
    """Test article retrieval from the RAG pipeline."""
    from backend.rag.pipeline import retrieve_context

    print("\n" + "=" * 60)
    print("ðŸ“š Ø§Ø®ØªØ¨Ø§Ø± Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù…ÙˆØ§Ø¯ (Article Retrieval)")
    print("=" * 60)

    passed = 0
    failed = 0
    results = []

    for test in ARTICLE_RETRIEVAL_TESTS:
        query = test["query"]
        expected_articles = set(test["expected_articles"])

        # Get retrieved context
        context = retrieve_context(query)

        # Extract article numbers from context
        retrieved_nums = set()
        for match in re.findall(r'Ø§Ù„Ù…Ø§Ø¯Ø©[:\s]+(\d+)', context):
            retrieved_nums.add(int(match))
        # Also check for "Ø§Ù„Ù…Ø§Ø¯Ø© (X)" format
        for match in re.findall(r'Ø§Ù„Ù…Ø§Ø¯Ø©\s*\((\d+)\)', context):
            retrieved_nums.add(int(match))
        # Check for article_number in the raw text
        for match in re.findall(r'"article_number":\s*(\d+)', context):
            retrieved_nums.add(int(match))

        # At least one expected article should be in retrieved
        hit = bool(expected_articles & retrieved_nums)

        if hit:
            passed += 1
            status = "âœ…"
        else:
            failed += 1
            status = "âŒ"
            print(f"  {status} {query[:50]}")
            print(f"       Ù…ØªÙˆÙ‚Ø¹: {expected_articles} | Ù…Ø³ØªØ±Ø¬Ø¹: {retrieved_nums}")

        results.append({
            "query": query,
            "expected": list(expected_articles),
            "retrieved": list(retrieved_nums),
            "passed": hit,
        })

    total = passed + failed
    pct = (passed / total * 100) if total else 0
    print(f"\nðŸ“Š Ø§Ù„Ù†ØªÙŠØ¬Ø©: {passed}/{total} ({pct:.0f}%)")

    return {"test": "article_retrieval", "passed": passed, "total": total, "pct": pct, "details": results}


def run_e2e_tests(api_url: str = None):
    """Run end-to-end tests against the full system."""
    print("\n" + "=" * 60)
    print("ðŸ”„ Ø§Ø®ØªØ¨Ø§Ø± Ø´Ø§Ù…Ù„ (End-to-End)")
    print("=" * 60)

    if api_url:
        print(f"   ðŸŒ API: {api_url}")
    else:
        # Use local imports
        from backend.services.legal_assistant import get_legal_response
        print("   ðŸ’» Ù…Ø­Ù„ÙŠ (local)")

    passed = 0
    failed = 0
    results = []

    for test in E2E_TESTS:
        query = test["query"]
        must_contain = test["must_contain"]
        must_not_contain = test["must_not_contain"]
        desc = test["description"]

        print(f"\n  ðŸ“ {desc}")
        print(f"     Ø³Ø¤Ø§Ù„: {query}")

        try:
            if api_url:
                resp = requests.post(
                    f"{api_url}/api/chat",
                    json={"message": query, "conversation_id": f"eval_{int(time.time())}"},
                    headers={"X-API-Key": os.getenv("API_KEY", "")},
                    timeout=60,
                )
                if resp.status_code == 200:
                    answer = resp.json().get("response", "")
                else:
                    answer = f"ERROR {resp.status_code}: {resp.text[:200]}"
            else:
                answer = get_legal_response(query)

            # Check must_contain
            missing = [w for w in must_contain if w not in answer]
            # Check must_not_contain
            found_bad = [w for w in must_not_contain if w in answer]

            test_passed = len(missing) == 0 and len(found_bad) == 0

            if test_passed:
                passed += 1
                print(f"     âœ… Ù†Ø¬Ø­")
            else:
                failed += 1
                if missing:
                    print(f"     âŒ Ù†Ø§Ù‚Øµ: {missing}")
                if found_bad:
                    print(f"     âŒ ÙŠØ­ØªÙˆÙŠ Ø®Ø·Ø£: {found_bad}")

            results.append({
                "query": query,
                "description": desc,
                "passed": test_passed,
                "missing": missing,
                "found_bad": found_bad,
                "answer_preview": answer[:200] if answer else "NO RESPONSE",
            })

            time.sleep(1)  # Rate limiting

        except Exception as e:
            failed += 1
            print(f"     âŒ Ø®Ø·Ø£: {e}")
            results.append({
                "query": query,
                "description": desc,
                "passed": False,
                "error": str(e),
            })

    total = passed + failed
    pct = (passed / total * 100) if total else 0
    print(f"\nðŸ“Š Ø§Ù„Ù†ØªÙŠØ¬Ø©: {passed}/{total} ({pct:.0f}%)")

    return {"test": "end_to_end", "passed": passed, "total": total, "pct": pct, "details": results}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MAIN
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

import re

def main():
    parser = argparse.ArgumentParser(description="Legal AI Evaluation System")
    parser.add_argument("--test", choices=["topics", "retrieval", "e2e", "all"], default="all")
    parser.add_argument("--api", type=str, default="", help="API URL for e2e tests (e.g., https://...onrender.com)")
    parser.add_argument("--output", type=str, default="", help="Save results to JSON file")
    args = parser.parse_args()

    print("âš–ï¸  Ù†Ø¸Ø§Ù… ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø³ØªØ´Ø§Ø± Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ø°ÙƒÙŠ")
    print("=" * 60)

    all_results = []

    if args.test in ("topics", "all"):
        all_results.append(run_topic_tests())

    if args.test in ("retrieval", "all"):
        all_results.append(run_retrieval_tests())

    if args.test in ("e2e", "all"):
        api_url = args.api or None
        all_results.append(run_e2e_tests(api_url))

    # Summary
    print("\n" + "=" * 60)
    print("ðŸ“Š Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
    print("=" * 60)

    total_passed = sum(r["passed"] for r in all_results)
    total_tests = sum(r["total"] for r in all_results)
    overall_pct = (total_passed / total_tests * 100) if total_tests else 0

    for r in all_results:
        icon = "âœ…" if r["pct"] >= 90 else "ðŸŸ¡" if r["pct"] >= 70 else "âŒ"
        print(f"  {icon} {r['test']}: {r['passed']}/{r['total']} ({r['pct']:.0f}%)")

    print(f"\n  ðŸ“Š Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {total_passed}/{total_tests} ({overall_pct:.0f}%)")
    grade = "A+" if overall_pct >= 95 else "A" if overall_pct >= 90 else "B" if overall_pct >= 80 else "C" if overall_pct >= 70 else "D"
    print(f"  ðŸ† Ø§Ù„ØªÙ‚Ø¯ÙŠØ±: {grade}")

    # Save results
    if args.output:
        output_path = Path(args.output)
    else:
        output_path = ROOT / "backend" / "data" / "eval_results.json"

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump({
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "summary": {
                "total_passed": total_passed,
                "total_tests": total_tests,
                "overall_pct": overall_pct,
                "grade": grade,
            },
            "results": all_results,
        }, f, ensure_ascii=False, indent=2)

    print(f"\n  ðŸ“ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø­ÙÙˆØ¸Ø©: {output_path}")

    return 0 if overall_pct >= 80 else 1


if __name__ == "__main__":
    sys.exit(main())
